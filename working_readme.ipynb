{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# **Decoding Data Jobs**\n",
    "##### *Analyzing job postings to find desired skill sets for aspiring data nerds.*\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    " \n",
    "Zacharia Schmitz<br>\n",
    "Joshua Click<br>\n",
    "October - November 2023<br>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![No picture yet](images/output.png)\n",
    "\n",
    "*Picture of dashboard deliverable when completed*\n",
    "\n",
    "</div>\n",
    "\n",
    "--- \n",
    "\n",
    "#### **Table of Contents:**\n",
    "\n",
    "###### *(Jump To)*\n",
    "\n",
    "[Project Overview](#overview)\n",
    "\n",
    "[Data Acquisition](#acquire)\n",
    "\n",
    "[Preparation](#preparing-data)\n",
    "\n",
    "[Exploration](#exploration-questions)\n",
    "\n",
    "[Models](#modeling)\n",
    "\n",
    "[Conclusion](#conclusions)\n",
    "\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "## **Overview**\n",
    "\n",
    "1. Decide Source\n",
    "\n",
    "2. Acquire Job Postings\n",
    "\n",
    "3. Data Cleaning\n",
    "\n",
    "4. Text Preprocessing\n",
    "\n",
    "5. Feature Extraction\n",
    "\n",
    "6. Model Training\n",
    "\n",
    "7. Dashboard (Presenting Model-Validated Findings)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Project Goal**\n",
    "\n",
    "**To develop a dynamic tool to assist aspiring Data Analysts to navigate the Job Market / Job Posts**\n",
    "\n",
    "--- \n",
    "\n",
    "## **Project Description**\n",
    "\n",
    "**Webscraping Google for job posts, analyzing these posts for most common skills / salaries / sectors / etc. and creating a dashboard for ease of access to visualize different aspects of the job postings**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Hypothesis**\n",
    "\n",
    "We can pull job postings for data analysts and specify where the jobs are coming from, most postings by location, salaries, and determine if they are scientist, engineer, or analyst positions. \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Acquire**\n",
    "\n",
    "#### *Rate Limits & Ethics*\n",
    "\n",
    "[**Google's Robots.txt**](google.com/robots.txt)\n",
    "\n",
    "```\n",
    "User-agent: *\n",
    "Disallow: /search\n",
    "\n",
    "```\n",
    "\n",
    "Google's Terms of Service explicitly disallow scraping of its services without permission. Scraping can lead to legal consequences. Although Google does not take legal action against scraping, it uses a range of defensive methods that makes scraping their results a challenging task, even when the scraping tool is realistically spoofing a normal web browser.\n",
    "\n",
    "Offending IPs and offending IP networks can easily be stored in a blacklist database to detect offenders much faster. Using a proxy or VPN is necessary for anything outside of human-like.\n",
    "\n",
    "We managed to very slowly scrape several hundred job postings using Selenium, but in order to perform accurate large scale analysis, we'd need much more time, or a much larger dataset.\n",
    "\n",
    "#### *Kaggle Dataset*\n",
    "\n",
    "While it was undesirable to use a public dataset for analysis, I was able to find a Kaggle dataset that has been updating daily for the past year. The dataset is currently around 150MB and 33,000 different job postings from around the United States.\n",
    "\n",
    "![Kaggle Dataset](https://www.kaggle.com/datasets/lukebarousse/data-analyst-job-postings-google-search)\n",
    "<br> <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Data Dictionary:**\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Alt text](images/datadict.png)\n",
    "\n",
    "### Definitions\n",
    "\n",
    "| Column | Definition |\n",
    "|--------|-----------|\n",
    "|`Unnamed: 0`|DROPPED - Extra column created when owner exported CSV|\n",
    "|`index`|DROPPED - Extra column created when owner exported CSV|\n",
    "|`title`|The job title from the job posting|\n",
    "|`company_name`|The company name from the job posting|\n",
    "|`location`|The location of the job from the posting|\n",
    "|`via`|The original posting location|\n",
    "|`description`|The job description from Google Jobs search|\n",
    "|`extensions`|Tags generated by Google, age of post, pay range, benefits, etc - will be parsed through|\n",
    "|`job_id`|Looks to be a unique ID for the job posting - will try to reverse engineer to be useful|\n",
    "|`thumbnail`|DROPPED - The thumbnail of the company from the Google Jobs posting|\n",
    "|`posted_at`|How long ago the job was posted, from time of scraping|\n",
    "|`schedule_type`|The working schedule of job - Ex: Full-time, part-time, etc.|\n",
    "|`work_from_home`|If the job is work from home aka remote|\n",
    "|`salary`|The pay for the postion - non-standardized (hourly, annual range, etc.)|\n",
    "|`search_term`|DROPPED - The original search term to find the job posting on Google Jobs|\n",
    "|`date_time`|The date/time that the job posting was pulled|\n",
    "|`search_location`|DROPPED - The country the search was filtered for (United States)|\n",
    "|`commute_time`|DROPPED - The commute time field from Google Jobs - Null only|\n",
    "|`salary_pay`|The pay for the postion - non-standardized (hourly, annual range, etc.)|\n",
    "|`salary_rate`|The rate of labeled pay - *hourly, weekly, monthly, annually*|\n",
    "|`salary_avg`|If provided a range, the average between the min and max|\n",
    "|`salary_min`|Lower end of the salary range, if available|\n",
    "|`salary_max`|Higher end of the salary range, if available|\n",
    "|`salary_hourly`|Hourly pay, if available|\n",
    "|`salary_yearly`|Annual salary, if available|\n",
    "|`salary_standardized`|Calculated annual salary, if any rate of pay is provided|\n",
    "|`description_tokens`|Tokenized skills pulled from description column|\n",
    "\n",
    "</div>\n",
    "\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Preparing Data**\n",
    "\n",
    "1. Redundant Columns\n",
    "\n",
    "    1. Dropped: 'Unnamed: 0', 'index', 'thumbnail', 'search_term', 'commute_time', 'search_location'\n",
    "\n",
    "    2. Dropped: 'salary_yearly', 'salary_hourly', 'salary_min', 'salary_max', 'salary_pay', 'salary_rate'\n",
    "\n",
    "2. Missing Data\n",
    "\n",
    "    1. Lots of Nulls in data for salary, work_from_home, location, via\n",
    "\n",
    "3. Data Transformation\n",
    "\n",
    "    1. Recreated the salary columns based off of annual salary or off of salary rate depending\n",
    "    2. Created 'title_cleaned' column\n",
    "    3. Dropped Rows that did not provide relevance to Data Analyst, Engineer, or Scientist\n",
    "\n",
    "4. Data Standardization\n",
    "\n",
    "    1. From the salary columns, ensured the ones that had the data were standard across the data.\n",
    "\n",
    "5. Data Encoding\n",
    "\n",
    "    5. \n",
    "\n",
    "6. Outliers\n",
    "\n",
    "    1. Focused on full-time positions to account for the contractor positions that were creating outliers from pay.\n",
    "\n",
    "7. Text Data Cleaning\n",
    "\n",
    "    1. Utilized regex to clean up the text data in 'description' column\n",
    "    2. Tokenized and Normalized text for NLP. \n",
    "\n",
    "8. Date Formatting\n",
    "\n",
    "    1. Converted the date_time, date_scraped, posted_at, posting_created to datetime\n",
    "\n",
    "9. Duplicate Data\n",
    "\n",
    "    9. Dropped Rows that shared the same 'job_id'\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Exploration Questions**\n",
    "\n",
    "1. What core job titles does our dataset consist of?\n",
    "\n",
    "2. What companies have the most job postings?\n",
    "\n",
    "3. What is the location spread for our dataset?\n",
    "\n",
    "4. Within the Google Jobs search, which site has the most postings? \n",
    "\n",
    "5. What sectors are hiring the most data analysts?\n",
    "\n",
    "6. What skills are most prevalent in our postings for programming languages, ML Algorithyms, tools? \n",
    "\n",
    "7. What does schedule_type look like throughout the dataset?\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Modeling**\n",
    "\n",
    "Utilize GridSearch for best parameters for TF-IDF and LogisticRegression\n",
    "\n",
    "```python\n",
    "# Grid Search Function\n",
    "\n",
    "```\n",
    "---\n",
    "\n",
    "### Best GridSearch:\n",
    "\n",
    "```python\n",
    "# Best Hyperparameters\n",
    "\n",
    "```\n",
    "\n",
    "**Baseline:**\n",
    "\n",
    "**Best cross-validation score:**\n",
    "\n",
    "**Train Set:**\n",
    "\n",
    "**Test Set:**\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **How to Reproduce:**\n",
    "\n",
    "1. Clone this repo (required CSV is in support_files)\n",
    "\n",
    "2. Run the notebook.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Conclusions**\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "##### - For Modeling:\n",
    "- Given the class imbalance, we used the precision metric and GridSearch to use the TF-IDF and Logistic Regression models\n",
    "    - ......\n",
    "\n",
    "##### - For Data Collection:\n",
    "- Decided to use the 'Full-Time' positions only to deal with outliers.\n",
    "- Trying to categorize by 'sector' proved to be too inaccurate from the nature of the descriptions in the job posts.\n",
    "- Dataset had very little job positions for engineer/scientists\n",
    "    - Propose including more engineer/scientist positions in the future datasets\n",
    "- 'Location' in the dataset was primarily from the \"Midwest\" and did not include positions from the entire U.S. as we were hoping.\n",
    "    - Propose webscraping separately than the sampleset we acquired to include more locations\n",
    "- Found that there is more jobs posted in the months of Dec-Jan for the past 2 years.\n",
    "- We were able to distiguish skills per analyst/engineer/scientist accurately\n",
    "- 'Salary' was only present in 18% of the data\n",
    "    - Propose trying to include more salary position info in the future.\n",
    "    - Known issue in the industry\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
