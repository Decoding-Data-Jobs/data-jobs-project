{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# **Decoding Data Jobs**\n",
    "##### *Analyzing job postings to find desired skill sets for aspiring data nerds.*\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    " \n",
    "Zacharia Schmitz<br>\n",
    "Joshua Click<br>\n",
    "October - November 2023<br>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![No picture yet](images/output.png)\n",
    "\n",
    "*Picture of dashboard deliverable when completed*\n",
    "\n",
    "</div>\n",
    "\n",
    "--- \n",
    "\n",
    "#### **Table of Contents:**\n",
    "\n",
    "###### *(Jump To)*\n",
    "\n",
    "[Project Overview](#overview)\n",
    "\n",
    "[Data Acquisition](#acquire)\n",
    "\n",
    "[Preparation](#preparing-data)\n",
    "\n",
    "[Exploration](#exploration-questions)\n",
    "\n",
    "[Models](#modeling)\n",
    "\n",
    "[Conclusion](#conclusions)\n",
    "\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "## **Overview**\n",
    "\n",
    "1. Decide Source\n",
    "\n",
    "2. Acquire Job Postings\n",
    "\n",
    "3. Data Cleaning\n",
    "\n",
    "4. Text Preprocessing\n",
    "\n",
    "5. Feature Extraction\n",
    "\n",
    "6. Model Training\n",
    "\n",
    "7. Dashboard (Presenting Model-Validated Findings)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Project Goal**\n",
    "\n",
    "**Goal Text Here**\n",
    "\n",
    "--- \n",
    "\n",
    "## **Project Description**\n",
    "\n",
    "**Description Here**\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Initial Questions and Hypotheses**\n",
    "\n",
    "1. Question 1\n",
    "\n",
    "    - Answer 1\n",
    "\n",
    "2. 2\n",
    "\n",
    "    - 2\n",
    "\n",
    "3. 3\n",
    "\n",
    "    - 3\n",
    "\n",
    "4. 4\n",
    "\n",
    "    - 4\n",
    "\n",
    "5. 5\n",
    "\n",
    "    - 5\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Acquire**\n",
    "\n",
    "#### *Rate Limits & Ethics*\n",
    "\n",
    "[**Google's Robots.txt**](google.com/robots.txt)\n",
    "\n",
    "```\n",
    "User-agent: *\n",
    "Disallow: /search\n",
    "\n",
    "```\n",
    "\n",
    "Google's Terms of Service explicitly disallow scraping of its services without permission. Scraping can lead to legal consequences. Although Google does not take legal action against scraping, it uses a range of defensive methods that makes scraping their results a challenging task, even when the scraping tool is realistically spoofing a normal web browser.\n",
    "\n",
    "Offending IPs and offending IP networks can easily be stored in a blacklist database to detect offenders much faster. Using a proxy or VPN is necessary for anything outside of human-like.\n",
    "\n",
    "We managed to very slowly scrape several hundred job postings using Selenium, but in order to perform accurate large scale analysis, we'd need much more time, or a much larger dataset.\n",
    "\n",
    "#### *Kaggle Dataset*\n",
    "\n",
    "While it was undesirable to use a public dataset for analysis, I was able to find a Kaggle dataset that has been updating daily for the past year. The dataset is currently around 150MB and 33,000 different job postings from around the United States.\n",
    "\n",
    "![Kaggle Dataset](https://www.kaggle.com/datasets/lukebarousse/data-analyst-job-postings-google-search)\n",
    "<br> <br>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Data Dictionary:**\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Alt text](images/datadict.png)\n",
    "\n",
    "### Definitions\n",
    "\n",
    "| Column | Definition |\n",
    "|--------|-----------|\n",
    "|`Unnamed: 0`|DROPPED - Extra column created when owner exported CSV|\n",
    "|`index`|DROPPED - Extra column created when owner exported CSV|\n",
    "|`title`|The job title from the job posting|\n",
    "|`company_name`|The company name from the job posting|\n",
    "|`location`|The location of the job from the posting|\n",
    "|`via`|The original posting location|\n",
    "|`description`|The job description from Google Jobs search|\n",
    "|`extensions`|Tags generated by Google, age of post, pay range, benefits, etc - will be parsed through|\n",
    "|`job_id`|Looks to be a unique ID for the job posting - will try to reverse engineer to be useful|\n",
    "|`thumbnail`|DROPPED - The thumbnail of the company from the Google Jobs posting|\n",
    "|`posted_at`|How long ago the job was posted, from time of scraping|\n",
    "|`schedule_type`|The working schedule of job - Ex: Full-time, part-time, etc.|\n",
    "|`work_from_home`|If the job is work from home aka remote|\n",
    "|`salary`|The pay for the postion - non-standardized (hourly, annual range, etc.)|\n",
    "|`search_term`|DROPPED - The original search term to find the job posting on Google Jobs|\n",
    "|`date_time`|The date/time that the job posting was pulled|\n",
    "|`search_location`|DROPPED - The country the search was filtered for (United States)|\n",
    "|`commute_time`|DROPPED - The commute time field from Google Jobs - Null only|\n",
    "|`salary_pay`|The pay for the postion - non-standardized (hourly, annual range, etc.)|\n",
    "|`salary_rate`|The rate of labeled pay - *hourly, weekly, monthly, annually*|\n",
    "|`salary_avg`|If provided a range, the average between the min and max|\n",
    "|`salary_min`|Lower end of the salary range, if available|\n",
    "|`salary_max`|Higher end of the salary range, if available|\n",
    "|`salary_hourly`|Hourly pay, if available|\n",
    "|`salary_yearly`|Annual salary, if available|\n",
    "|`salary_standardized`|Calculated annual salary, if any rate of pay is provided|\n",
    "|`description_tokens`|Tokenized skills pulled from description column|\n",
    "\n",
    "</div>\n",
    "\n",
    "</p>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Preparing Data**\n",
    "\n",
    "*prep steps here*\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "## **Exploration Questions**\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n",
    "4. \n",
    "\n",
    "5. \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Modeling**\n",
    "\n",
    "Utilize GridSearch for best parameters for TF-IDF and LogisticRegression\n",
    "\n",
    "```python\n",
    "# Grid Search Function\n",
    "\n",
    "```\n",
    "---\n",
    "\n",
    "### Best GridSearch:\n",
    "\n",
    "```python\n",
    "# Best Hyperparameters\n",
    "\n",
    "```\n",
    "\n",
    "**Baseline:**\n",
    "\n",
    "**Best cross-validation score:**\n",
    "\n",
    "**Train Set:**\n",
    "\n",
    "**Test Set:**\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## **How to Reproduce:**\n",
    "\n",
    "1. Clone this repo (required CSV is in support_files)\n",
    "\n",
    "2. Run the notebook.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Conclusions**\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "##### - For Modeling:\n",
    "\n",
    "\n",
    "##### - For Data Collection:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
